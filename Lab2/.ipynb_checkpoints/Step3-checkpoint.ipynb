{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec 17 17:58:26 2020\n",
    "@author: Francesco Conforte\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo as pm\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter, DayLocator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client = pm.MongoClient('bigdatadb.polito.it',<br>\n",
    "                        ssl=True,<br>\n",
    "                        authSource = 'carsharing',<br>\n",
    "                        tlsAllowInvalidCertificates=True)<br>\n",
    "db = client['carsharing'] #Choose the DB to use<br>\n",
    "db.authenticate('ictts', 'Ictts16!')#, mechanism='MONGODB-CR') #authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start = datetime(2017,1,7,0,0,0) <br>\n",
    "end = datetime(2017,2,5,23,59,59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cars_per_hour_filtered_list=[]<br>\n",
    "cities = [\"Milano\", \"Calgary\", \"Amsterdam\"]<br>\n",
    "for c in cities:<br>\n",
    "    cars_per_hour_filtered = db.get_collection(\"PermanentBookings\").aggregate(<br>\n",
    "          [<br>\n",
    "             { \"$match\" : {\"$and\": [ { \"city\": c },<br>\n",
    "                                     { \"init_date\": { \"$gte\": start } },<br>\n",
    "                                     { \"final_date\": { \"$lte\": end } },<br>\n",
    "                                  ]<br>\n",
    "                         } <br>\n",
    "             },<br>\n",
    "             { \"$project\": {<br>\n",
    "                   \"_id\": 1,<br>\n",
    "                   \"city\": 1,<br>\n",
    "                   \"moved\": { \"$ne\": [<br>\n",
    "                         {\"$arrayElemAt\": [ \"$origin_destination.coordinates\", 0]},<br>\n",
    "                         {\"$arrayElemAt\": [ \"$origin_destination.coordinates\", 1]} <br>\n",
    "                      ]<br>\n",
    "                   },<br>\n",
    "                   \"duration\": { \"$divide\": [ { \"$subtract\": [\"$final_time\", \"$init_time\"] }, 60 ] },<br>\n",
    "                   \"date_parts\": { \"$dateToParts\": { \"date\": \"$init_date\" } },<br>\n",
    "                }<br>\n",
    "             },<br>\n",
    "             { \"$match\" : { \"$and\": [ { \"duration\": { \"$gte\": 3 } },<br>\n",
    "                                        { \"duration\": { \"$lte\": 180 } },<br>\n",
    "                                        { \"moved\": True }<br>\n",
    "                                     ] <br>\n",
    "                            }<br>\n",
    "             },<br>\n",
    "             { \"$group\": {<br>\n",
    "                   \"_id\": {<br>\n",
    "                      \"day\": \"$date_parts.day\",<br>\n",
    "                      \"month\":\"$date_parts.month\",<br>\n",
    "                      \"hour\": \"$date_parts.hour\"<br>\n",
    "                   },<br>\n",
    "                   \"tot_rentals\": {\"$sum\": 1}<br>\n",
    "             }<br>\n",
    "             },<br>\n",
    "             { \"$sort\": {\"_id\": 1} }<br>\n",
    "          ]<br>\n",
    "       )<br>\n",
    "    cars_per_hour_filtered_list.append(list(cars_per_hour_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# cars_per_hour_Milano = cars_per_hour_filtered_list[0]\n",
    "# cars_per_hour_Calgary = cars_per_hour_filtered_list[1]\n",
    "# cars_per_hour_Amsterdam = cars_per_hour_filtered_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#%%check missing data for Calgary<br>\n",
    "days=[]  <br>\n",
    "rentals_Calgary=[]   <br>\n",
    "for i in range(len(cars_per_hour_Calgary)):<br>\n",
    "    days.append(datetime(2017,cars_per_hour_Calgary[i]['_id']['month'],<br>\n",
    "                          cars_per_hour_Calgary[i]['_id']['day'],<br>\n",
    "                          cars_per_hour_Calgary[i]['_id']['hour']))<br>\n",
    "    rentals_Calgary.append(cars_per_hour_Calgary[i]['tot_rentals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calgary=pd.DataFrame({'days':days,'rentals':rentals_Calgary},index=days) <br>\n",
    "missing_Calgary=pd.date_range(start = '2017-01-07', end = '2017-02-05', <br>\n",
    "                              freq='H' ).difference(Calgary.index) #find missing hours<br>\n",
    "Calgary=Calgary.sort_index()<br>\n",
    "#add missing data for Calgary<br>\n",
    "Nr=missing_Calgary.shape[0]<br>\n",
    "if Nr>0:<br>\n",
    "    missing_data=pd.DataFrame({'days':missing_Calgary,'rentals':np.full(Nr,-1)},<br>\n",
    "                              index=missing_Calgary.values)#add 0 as temp value<br>\n",
    "    Calgary=Calgary.append(missing_data)#add the two missing values to main Dataset<br>\n",
    "    Calgary=Calgary.sort_index()#sort rows to put new rows to right place<br>\n",
    "    index=np.argwhere((Calgary['rentals'].values==-1)) #find index where rentals are 0<br>\n",
    "    Calgary['rentals'].values[index]=(Calgary['rentals'].values[index-1]+<br>\n",
    "                               Calgary['rentals'].values[index+1])//2 #use mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#%%check missing data for Milano<br>\n",
    "days=[] <br>\n",
    "rentals_Milano=[]    <br>\n",
    "for i in range(len(cars_per_hour_Milano)):<br>\n",
    "    days.append(datetime(2017,cars_per_hour_Milano[i]['_id']['month'],<br>\n",
    "                          cars_per_hour_Milano[i]['_id']['day'],<br>\n",
    "                          cars_per_hour_Milano[i]['_id']['hour']))<br>\n",
    "    rentals_Milano.append(cars_per_hour_Milano[i]['tot_rentals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milano=pd.DataFrame({'days':days,'rentals':rentals_Milano},index=days)<br>\n",
    "missing_Milano=pd.date_range(start = '2017-01-07', end = '2017-02-05', <br>\n",
    "                             freq='H' ).difference(Milano.index)<br>\n",
    "Milano=Milano.sort_index()<br>\n",
    "#add missing data for Milano<br>\n",
    "Nr=missing_Milano.shape[0]<br>\n",
    "if Nr>0:<br>\n",
    "    missing_data=pd.DataFrame({'days':missing_Milano,'rentals':np.full(Nr,-1)},<br>\n",
    "                              index=missing_Milano.values)#add 0 as temp value<br>\n",
    "    Milano=Milano.append(missing_data)#add the two missing values to main Dataset<br>\n",
    "    Milano=Milano.sort_index()#sort rows to put new rows to right place<br>\n",
    "    index=np.argwhere((Milano['rentals'].values==-1)) #find index where rentals are 0<br>\n",
    "    Milano['rentals'].values[index]=(Milano['rentals'].values[index-1]+<br>\n",
    "                               Milano['rentals'].values[index+1])//2 #use mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#%%check missing data for Amsterdam<br>\n",
    "days=[] <br>\n",
    "rentals_Amsterdam=[]    <br>\n",
    "for i in range(len(cars_per_hour_Amsterdam)):<br>\n",
    "    days.append(datetime(2017,cars_per_hour_Amsterdam[i]['_id']['month'],<br>\n",
    "                          cars_per_hour_Amsterdam[i]['_id']['day'],<br>\n",
    "                          cars_per_hour_Amsterdam[i]['_id']['hour']))<br>\n",
    "    rentals_Amsterdam.append(cars_per_hour_Amsterdam[i]['tot_rentals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amsterdam=pd.DataFrame({'days':days,'rentals':rentals_Amsterdam},index=days)<br>\n",
    "missing_Amsterdam=pd.date_range(start = '2017-01-07', end = '2017-02-05', <br>\n",
    "                                freq='H' ).difference(Amsterdam.index)<br>\n",
    "Amsterdam=Amsterdam.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#add missing data for Amsterdam<br>\n",
    "Nr=missing_Amsterdam.shape[0]<br>\n",
    "if Nr>0:<br>\n",
    "    missing_data=pd.DataFrame({'days':missing_Amsterdam,'rentals':np.full(Nr,-1)},<br>\n",
    "                              index=missing_Amsterdam.values)#add 0 as temp value<br>\n",
    "    Amsterdam=Amsterdam.append(missing_data)#add the two missing values to main Dataset<br>\n",
    "    Amsterdam=Amsterdam.sort_index()#sort rows to put new rows to right place<br>\n",
    "    index=np.argwhere((Amsterdam['rentals'].values==-1)) #find index where rentals are 0<br>\n",
    "    Amsterdam['rentals'].values[index]=(Amsterdam['rentals'].values[index-1]+<br>\n",
    "                               Amsterdam['rentals'].values[index+1])//2 #use mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calgary.to_csv('calgary.csv', index=False)<br>\n",
    "Milano.to_csv('milano.csv', index=False)<br>\n",
    "Amsterdam.to_csv('amsterdam.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calgary = pd.read_csv('calgary.csv',sep=',',parse_dates=[0],index_col=0)\n",
    "Milano = pd.read_csv('milano.csv',sep=',',parse_dates=[0],index_col=0)\n",
    "Amsterdam = pd.read_csv('amsterdam.csv',sep=',',parse_dates=[0],index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% CHECK OF STATIONARITY<br>\n",
    "heck the stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Calgary.index.values,Calgary[\"rentals\"].values,label='real rentals')\n",
    "rolling_mean_calgary=Calgary['rentals'].rolling(168).mean()# 168 is 24*1week\n",
    "rolling_std_calgary=Calgary['rentals'].rolling(168).std()# 168 is 24*1week\n",
    "ax.plot(rolling_mean_calgary,label='rolling mean')\n",
    "ax.plot(rolling_std_calgary,label='rolling std')\n",
    "ax.legend(ncol=1,fontsize='small')\n",
    "fig.autofmt_xdate()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "plt.title('Rolling statistics Calgary (1 week sliding window)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#since the trend is not stationary, we differentaite 1 time<br>\n",
    "Calgary_diff = Calgary['rentals'].diff()<br>\n",
    "fig, ax = plt.subplots()<br>\n",
    "ax.plot(Calgary.index.values,Calgary_diff.values,label='real rentals')<br>\n",
    "rolling_mean_calgary=Calgary_diff.rolling(168).mean()# 168 is 24*1week<br>\n",
    "rolling_std_calgary=Calgary_diff.rolling(168).std()# 168 is 24*1week<br>\n",
    "ax.plot(rolling_mean_calgary,label='rolling mean')<br>\n",
    "ax.plot(rolling_std_calgary,label='rolling std')<br>\n",
    "ax.legend(ncol=1,fontsize='small')<br>\n",
    "fig.autofmt_xdate()<br>\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M:%S'))<br>\n",
    "plt.title('Rolling statistics Calgary (1 week sliding window)')<br>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Milano.index.values,Milano[\"rentals\"].values,label='real rentals')\n",
    "rolling_mean_milano=Milano['rentals'].rolling(168).mean()\n",
    "rolling_std_milano=Milano['rentals'].rolling(168).std()# 168 is 24*1week\n",
    "ax.plot(rolling_mean_milano,label='rolling mean')\n",
    "ax.plot(rolling_std_milano,label='rolling std')\n",
    "ax.legend(ncol=1,fontsize='small')\n",
    "fig.autofmt_xdate()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "plt.title('Rolling statistics Milano (1 week sliding window)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Amsterdam.index.values,Amsterdam[\"rentals\"].values,label='real rentals')\n",
    "rolling_mean_amsterdam=Amsterdam['rentals'].rolling(168).mean()\n",
    "rolling_std_amsterdam=Amsterdam['rentals'].rolling(168).std()# 168 is 24*1week\n",
    "ax.plot(rolling_mean_amsterdam,label='rolling mean')\n",
    "ax.plot(rolling_std_amsterdam,label='rolling std')\n",
    "ax.legend(ncol=1,fontsize='small')\n",
    "fig.autofmt_xdate()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "plt.title('Rolling statistics Amsterdam (1 week sliding window)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% ACF AND PACF<br>\n",
    "lot ACF and PACF for Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(Amsterdam.rentals.values, lags=28, title='Autocorrelation for Amsterdam')\n",
    "sm.graphics.tsa.plot_pacf(Amsterdam.rentals.values, lags=28, title='Partial Autocorrelation for Amsterdam')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lot ACF and PACF for Calgary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(Calgary.rentals.values, lags=28, title='Autocorrelation for Calgary')\n",
    "sm.graphics.tsa.plot_pacf(Calgary.rentals.values, lags=28, title='Partial Autocorrelation for Calgary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lot ACF and PACF for Milano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(Milano.rentals.values, lags=28, title='Autocorrelation for Milano')\n",
    "sm.graphics.tsa.plot_pacf(Milano.rentals.values, lags=28, title='Partial Autocorrelation for Milano')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% FIT THE MODEL without dicision in test and training<br>\n",
    "msterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(Amsterdam.astype(float), order=(2,0,1))\n",
    "model_fit = model.fit(disp=0,method='css')\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Amsterdam.index.values,Amsterdam.rentals.values,label='real rentals')\n",
    "ax.plot(model_fit.fittedvalues, color='red', label='predicted values')\n",
    "ax.legend(ncol=1,fontsize='small')\n",
    "fig.autofmt_xdate()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "plt.title('Real reltals vs Predicted Values with ARIMA(2,0,1) for Amsterdam')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(Calgary.astype(float), order=(2,0,1))\n",
    "model_fit = model.fit(disp=0,method='css')\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Calgary.index.values,Calgary.rentals.values,label='real rentals')\n",
    "ax.plot(model_fit.fittedvalues, color='red', label='predicted values')\n",
    "ax.legend(ncol=1,fontsize='small')\n",
    "fig.autofmt_xdate()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "plt.title('Real reltals vs Predicted Values with ARIMA(2,0,1) for Calgary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ilano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(Milano.astype(float), order=(2,0,1))\n",
    "model_fit = model.fit(disp=0,method='css')\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Milano.index.values,Milano.rentals.values,label='real rentals')\n",
    "ax.plot(model_fit.fittedvalues, color='red', label='predicted values')\n",
    "ax.legend(ncol=1,fontsize='small')\n",
    "fig.autofmt_xdate()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "plt.title('Real reltals vs Predicted Values with ARIMA(2,0,1) for Milano')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%Fit the model with division in training and test<br>\n",
    "msterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_am = Amsterdam.values.astype(float)\n",
    "tr_size_am = 504 #size train (504h=3 week)\n",
    "ts_size_am = 72 #size test (72h = 3 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_am, test_am = X_am[0:tr_size_am], X_am[tr_size_am:(tr_size_am+ts_size_am)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [x for x in train_am]\n",
    "predictions=[]\n",
    "for t in range(0, ts_size_am):#for each hour I do arima model\n",
    "    model = ARIMA(history, order=(2,0,1))\n",
    "    model_fit = model.fit(disp=0,method='css')\n",
    "    output = model_fit.forecast() #get all the forecast\n",
    "     \n",
    "    yhat = output[0] #first forecast\n",
    "    predictions.append(yhat)\n",
    "     \n",
    "    obs = test_am[t]\n",
    "    history.append(obs)\n",
    "        \n",
    "        \n",
    "plt.plot(test_am, color='black')\n",
    "print('(2,0,1) model => MAE: %.3f -- MSE: %.3f -- MAPE: %.3f -- R2: %.3f' %(\n",
    "    mean_absolute_error(test_am, predictions),\n",
    "\tmean_squared_error(test_am, predictions),\n",
    "    mean_absolute_percentage_error(test_am, predictions),\n",
    "\tr2_score(test_am, predictions)))\n",
    "plt.plot(predictions, label = 'p=2 Amsterdam')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ca = Calgary.values.astype(float)\n",
    "tr_size_ca = 504 #size train (504h=3 week)\n",
    "ts_size_ca = 72 #size test (72h = 3 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ca, test_ca = X_ca[0:tr_size_ca], X_ca[tr_size_ca:(tr_size_ca+ts_size_ca)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [x for x in train_ca]\n",
    "predictions=[]\n",
    "for t in range(0, ts_size_ca):#for each hour I do arima model\n",
    "    model = ARIMA(history, order=(2,0,1))\n",
    "    model_fit = model.fit(disp=0,method='css')\n",
    "    output = model_fit.forecast() #get all the forecast\n",
    "     \n",
    "    yhat = output[0] #first forecast\n",
    "    predictions.append(yhat)\n",
    "     \n",
    "    obs = test_ca[t]\n",
    "    history.append(obs)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_ca, color='black')\n",
    "print('(2,0,1) model => MAE: %.3f -- MSE: %.3f -- MAPE: %.3f -- R2: %.3f' %(\n",
    "    mean_absolute_error(test_ca, predictions),\n",
    "\tmean_squared_error(test_ca, predictions),\n",
    "    mean_absolute_percentage_error(test_ca, predictions),\n",
    "\tr2_score(test_ca, predictions)))\n",
    "plt.plot(predictions, label = 'p=2 Calgary')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ilano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mi = Milano.values.astype(float)\n",
    "tr_size_mi = 336 #size train (504h=3 week)\n",
    "ts_size_mi = 72 #size test (72h = 3 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mi, test_mi = X_mi[0:tr_size_mi], X_mi[tr_size_mi:(tr_size_mi+ts_size_mi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [x for x in train_mi]\n",
    "predictions=[]\n",
    "for t in range(0, ts_size_mi):#for each hour I do arima model\n",
    "    model = ARIMA(history, order=(2,0,1))\n",
    "    model_fit = model.fit(disp=0,method='css')\n",
    "    output = model_fit.forecast() #get all the forecast\n",
    "     \n",
    "    yhat = output[0] #first forecast\n",
    "    predictions.append(yhat)\n",
    "     \n",
    "    obs = test_mi[t]\n",
    "    history.append(obs)\n",
    "        \n",
    "        \n",
    "plt.plot(test_mi, color='black', label='Orig')\n",
    "print('(2,0,1) model => MAE: %.3f -- MSE: %.3f -- MAPE: %.3f -- R2: %.3f' %(\n",
    "    mean_absolute_error(test_mi, predictions),\n",
    "\tmean_squared_error(test_mi, predictions),\n",
    "    mean_absolute_percentage_error(test_mi, predictions),\n",
    "\tr2_score(test_mi, predictions)))\n",
    "plt.plot(predictions, label = 'p=2 Milano')\n",
    "plt.title('ARIMA(2,0,1) with expanding window')\n",
    "plt.legend(ncol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%Fit the model with a grid search over p and q with train and test fixed<br>\n",
    "Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = range(1,7) #y axis\n",
    "q_values = range(1,6) #x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_am = Amsterdam.values.astype(float)\n",
    "tr_size_am = 504 #size train (504h=3 week)\n",
    "ts_size_am = 72 #size test (72h = 3 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_am, test_am = X_am[0:tr_size_am], X_am[tr_size_am:(tr_size_am+ts_size_am)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.zeros((len(p_values),len(q_values),ts_size_am))\n",
    "MAE=np.zeros((len(p_values),len(q_values)))\n",
    "MSE=np.zeros((len(p_values),len(q_values)))\n",
    "MAPE=np.zeros((len(p_values),len(q_values)))\n",
    "R2=np.zeros((len(p_values),len(q_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_values:\n",
    "    for q in q_values:\n",
    "        print('Testing ARIMA order (%i,0,%i)' %(p,q))\n",
    "        history = [x for x in train_am]\n",
    "        for t in range(0, ts_size_am):#for each hour I do arima model\n",
    "            model = ARIMA(history, order=(p,0,q))\n",
    "            model_fit = model.fit(disp=0,method='css')\n",
    "            output = model_fit.forecast() #get all the forecast\n",
    "             \n",
    "            yhat = output[0] #first forecast\n",
    "            predictions[p_values.index(p)][q_values.index(q)][t]=yhat\n",
    "             \n",
    "            obs = test_am[t]\n",
    "            history.append(obs)\n",
    "        MAE[p_values.index(p)][q_values.index(q)]=mean_absolute_error(\n",
    "            test_am, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        MSE[p_values.index(p)][q_values.index(q)]=mean_squared_error(\n",
    "            test_am, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        MAPE[p_values.index(p)][q_values.index(q)]=mean_absolute_percentage_error(\n",
    "            test_am, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        R2[p_values.index(p)][q_values.index(q)]=r2_score(\n",
    "            test_am, predictions[p_values.index(p)][q_values.index(q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = sb.heatmap(MAPE,xticklabels=q_values,yticklabels=p_values,annot=True)\n",
    "heat_map.set_title('MAPE: Expanding window for different value of p and q Amsterdam')\n",
    "heat_map.set_xlabel('q')\n",
    "heat_map.set_ylabel('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.argwhere(MAPE == np.amin(MAPE))[0]\n",
    "print('-----Amsterdam-----')\n",
    "print('p best is: ' + str(p_values[ind[0]]))\n",
    "print('q best is: ' + str(q_values[ind[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calgary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = range(1,7) #y axis\n",
    "q_values = range(1,6) #x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ca = Calgary.values.astype(float)\n",
    "tr_size_ca = 504 #size train (504h=3 week)\n",
    "ts_size_ca = 72 #size test (72h = 3 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ca, test_ca = X_ca[0:tr_size_ca], X_ca[tr_size_ca:(tr_size_ca+ts_size_ca)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.zeros((len(p_values),len(q_values),ts_size_ca))\n",
    "MAE=np.zeros((len(p_values),len(q_values)))\n",
    "MSE=np.zeros((len(p_values),len(q_values)))\n",
    "MAPE=np.zeros((len(p_values),len(q_values)))\n",
    "R2=np.zeros((len(p_values),len(q_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_values:\n",
    "    for q in q_values:\n",
    "        print('Testing ARIMA order (%i,0,%i)' %(p,q))\n",
    "        history = [x for x in train_ca]\n",
    "        for t in range(0, ts_size_ca):#for each hour I do arima model\n",
    "            model = ARIMA(history, order=(p,0,q))\n",
    "            model_fit = model.fit(disp=0,method='css')\n",
    "            output = model_fit.forecast() #get all the forecast\n",
    "             \n",
    "            yhat = output[0] #first forecast\n",
    "            predictions[p_values.index(p)][q_values.index(q)][t]=yhat\n",
    "             \n",
    "            obs = test_ca[t]\n",
    "            history.append(obs)\n",
    "        MAE[p_values.index(p)][q_values.index(q)]=mean_absolute_error(\n",
    "            test_ca, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        MSE[p_values.index(p)][q_values.index(q)]=mean_squared_error(\n",
    "            test_ca, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        MAPE[p_values.index(p)][q_values.index(q)]=mean_absolute_percentage_error(\n",
    "            test_ca, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        R2[p_values.index(p)][q_values.index(q)]=r2_score(\n",
    "            test_ca, predictions[p_values.index(p)][q_values.index(q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = sb.heatmap(MAPE,xticklabels=q_values,yticklabels=p_values,annot=True)\n",
    "heat_map.set_title('MAPE: Expanding window for different value of p and q Calgary')\n",
    "heat_map.set_xlabel('q')\n",
    "heat_map.set_ylabel('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.argwhere(MAPE == np.amin(MAPE))[0]\n",
    "print('-----Calgary-----')\n",
    "print('p best is: ' + str(p_values[ind[0]]))\n",
    "print('q best is: ' + str(q_values[ind[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = range(1,6) #y axis\n",
    "q_values = range(1,5) #x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mi = Milano.values.astype(float)\n",
    "tr_size_mi = 504 #size train (504h=3 week)\n",
    "ts_size_mi = 72 #size test (72h = 3 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mi, test_mi = X_mi[0:tr_size_mi], X_mi[tr_size_mi:(tr_size_mi+ts_size_mi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.zeros((len(p_values),len(q_values),ts_size_mi))\n",
    "MAE=np.zeros((len(p_values),len(q_values)))\n",
    "MSE=np.zeros((len(p_values),len(q_values)))\n",
    "MAPE=np.zeros((len(p_values),len(q_values)))\n",
    "R2=np.zeros((len(p_values),len(q_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_values:\n",
    "    for q in q_values:\n",
    "        print('Testing ARIMA order (%i,0,%i)' %(p,q))\n",
    "        history = [x for x in train_mi]\n",
    "        for t in range(0, ts_size_mi):#for each hour I do arima model\n",
    "            model = ARIMA(history, order=(p,0,q))\n",
    "            model_fit = model.fit(disp=0,method='css')\n",
    "            output = model_fit.forecast() #get all the forecast\n",
    "             \n",
    "            yhat = output[0] #first forecast\n",
    "            predictions[p_values.index(p)][q_values.index(q)][t]=yhat\n",
    "             \n",
    "            obs = test_mi[t]\n",
    "            history.append(obs)\n",
    "        MAE[p_values.index(p)][q_values.index(q)]=mean_absolute_error(\n",
    "            test_mi, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        MSE[p_values.index(p)][q_values.index(q)]=mean_squared_error(\n",
    "            test_mi, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        MAPE[p_values.index(p)][q_values.index(q)]=mean_absolute_percentage_error(\n",
    "            test_mi, predictions[p_values.index(p)][q_values.index(q)])\n",
    "        R2[p_values.index(p)][q_values.index(q)]=r2_score(\n",
    "            test_mi, predictions[p_values.index(p)][q_values.index(q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = sb.heatmap(MAPE,xticklabels=q_values,yticklabels=p_values,annot=True)\n",
    "heat_map.set_title('MAPE: Expanding window for different value of p and q Milano')\n",
    "heat_map.set_xlabel('q')\n",
    "heat_map.set_ylabel('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.argwhere(MAPE == np.amin(MAPE))[0]\n",
    "print('-----Milano-----')\n",
    "print('p best is: ' + str(p_values[ind[0]]))\n",
    "print('q best is: ' + str(q_values[ind[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%Fit the model for different sizes of training. Expanding + Sliding window<br>\n",
    "Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_am = Amsterdam.values.astype(float)\n",
    "methods = [0,1] #0 expanding; 1 sliding\n",
    "tr_size_am = 504 #size train (504h=3 week)\n",
    "ts_size_am = 72 #size test (168h = 1 week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values = list(np.linspace(72,tr_size_am,num=19, dtype=int)) \n",
    "predictions=np.zeros((len(N_values),len(methods),ts_size_am))\n",
    "MAE=np.zeros((len(N_values),len(methods)))\n",
    "MSE=np.zeros((len(N_values),len(methods)))\n",
    "MAPE=np.zeros((len(N_values),len(methods)))\n",
    "R2=np.zeros((len(N_values),len(methods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in methods:\n",
    "    for j in N_values:\n",
    "        print('Testing method %s and training size %i' %(m,j))\n",
    "        train_am, test_am = X_am[0:j], X_am[j:(j+ts_size_am)]\n",
    "        history = [x for x in train_am]\n",
    "        for t in range(0, ts_size_am):#for each hour I do arima model\n",
    "            model = ARIMA(history, order=(4,0,2))\n",
    "            model_fit = model.fit(disp=0, method='css')\n",
    "            output = model_fit.forecast() #get all the forecast\n",
    "             \n",
    "            yhat = output[0] #first forecast\n",
    "            predictions[N_values.index(j)][methods.index(m)][t]=yhat\n",
    "             \n",
    "            obs = test_am[t]\n",
    "            history.append(obs)\n",
    "            history=history[m:]\n",
    "        MAE[N_values.index(j)][methods.index(m)]=mean_absolute_error(\n",
    "            test_am, predictions[N_values.index(j)][methods.index(m)])\n",
    "        MSE[N_values.index(j)][methods.index(m)]=mean_squared_error(\n",
    "            test_am, predictions[N_values.index(j)][methods.index(m)])\n",
    "        MAPE[N_values.index(j)][methods.index(m)]=mean_absolute_percentage_error(\n",
    "            test_am, predictions[N_values.index(j)][methods.index(m)])\n",
    "        R2[N_values.index(j)][methods.index(m)]=r2_score(\n",
    "            test_am, predictions[N_values.index(j)][methods.index(m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = sb.heatmap(MAPE,xticklabels=methods,yticklabels=N_values,annot=True)\n",
    "heat_map.set_title('MAPE for different sizes of training and with expanding and sliding methods for Amsterdam')\n",
    "heat_map.set_xticklabels(['Expanding','Sliding'])\n",
    "heat_map.set_ylabel('Number of Training Values [Hours]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(N_values, MAPE[:,0],label='Expanding')\n",
    "plt.plot(N_values, MAPE[:,1],label='Sliding')\n",
    "plt.xlabel('Number of Training Values [Hours]')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('MAPE vs Learning strategy and Training size Amsterdam')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calgary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "X_ca = Calgary.values.astype(float)\n",
    "methods = [0,1] #0 expanding; 1 sliding\n",
    "tr_size_ca = 504 #size train (504h=3 week)\n",
    "ts_size_ca = 72 #size test (168h = 1 week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values = list(np.linspace(72,tr_size_ca,num=19, dtype=int)) \n",
    "predictions=np.zeros((len(N_values),len(methods),ts_size_ca))\n",
    "MAE=np.zeros((len(N_values),len(methods)))\n",
    "MSE=np.zeros((len(N_values),len(methods)))\n",
    "MAPE=np.zeros((len(N_values),len(methods)))\n",
    "R2=np.zeros((len(N_values),len(methods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in methods:\n",
    "    for j in N_values:\n",
    "        print('Testing method %s and training size %i' %(m,j))\n",
    "        train_ca, test_ca = X_ca[0:j], X_ca[j:(j+ts_size_ca)]\n",
    "        history = [x for x in train_ca]\n",
    "        for t in range(0, ts_size_ca):#for each hour I do arima model\n",
    "            model = ARIMA(history, order=(5,0,2))\n",
    "            model_fit = model.fit(disp=0, method='css')\n",
    "            output = model_fit.forecast() #get all the forecast\n",
    "             \n",
    "            yhat = output[0] #first forecast\n",
    "            predictions[N_values.index(j)][methods.index(m)][t]=yhat\n",
    "             \n",
    "            obs = test_ca[t]\n",
    "            history.append(obs)\n",
    "            history=history[m:]\n",
    "        MAE[N_values.index(j)][methods.index(m)]=mean_absolute_error(\n",
    "            test_ca, predictions[N_values.index(j)][methods.index(m)])\n",
    "        MSE[N_values.index(j)][methods.index(m)]=mean_squared_error(\n",
    "            test_ca, predictions[N_values.index(j)][methods.index(m)])\n",
    "        MAPE[N_values.index(j)][methods.index(m)]=mean_absolute_percentage_error(\n",
    "            test_ca, predictions[N_values.index(j)][methods.index(m)])\n",
    "        R2[N_values.index(j)][methods.index(m)]=r2_score(\n",
    "            test_ca, predictions[N_values.index(j)][methods.index(m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = sb.heatmap(MAPE,xticklabels=methods,yticklabels=N_values,annot=True)\n",
    "heat_map.set_title('MAPE for different sizes of training and with expanding and sliding methods for Calgary')\n",
    "heat_map.set_xticklabels(['Expanding','Sliding'])\n",
    "heat_map.set_ylabel('Number of Training Values [Hours]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(N_values, MAPE[:,0],label='Expanding')\n",
    "plt.plot(N_values, MAPE[:,1],label='Sliding')\n",
    "plt.xlabel('Number of Training Values [Hours]')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('MAPE vs Learning strategy and Training size Calgary')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mi = Milano.values.astype(float)\n",
    "methods = [0,1] #0 expanding; 1 sliding\n",
    "tr_size_mi = 504 #size train (504h=3 week)\n",
    "ts_size_mi = 72 #size test (168h = 1 week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values = list(np.linspace(72,tr_size_mi,num=19, dtype=int)) \n",
    "predictions=np.zeros((len(N_values),len(methods),ts_size_mi))\n",
    "MAE=np.zeros((len(N_values),len(methods)))\n",
    "MSE=np.zeros((len(N_values),len(methods)))\n",
    "MAPE=np.zeros((len(N_values),len(methods)))\n",
    "R2=np.zeros((len(N_values),len(methods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in methods:\n",
    "    for j in N_values:\n",
    "        print('Testing method %s and training size %i' %(m,j))\n",
    "        train_mi, test_mi = X_mi[0:j], X_mi[j:(j+ts_size_mi)]\n",
    "        history = [x for x in train_mi]\n",
    "        for t in range(0, ts_size_mi):#for each hour I do arima model\n",
    "            model = ARIMA(history, order=(4,0,1))\n",
    "            model_fit = model.fit(disp=0, method='css')\n",
    "            output = model_fit.forecast() #get all the forecast\n",
    "             \n",
    "            yhat = output[0] #first forecast\n",
    "            predictions[N_values.index(j)][methods.index(m)][t]=yhat\n",
    "             \n",
    "            obs = test_mi[t]\n",
    "            history.append(obs)\n",
    "            history=history[m:]\n",
    "        MAE[N_values.index(j)][methods.index(m)]=mean_absolute_error(\n",
    "            test_mi, predictions[N_values.index(j)][methods.index(m)])\n",
    "        MSE[N_values.index(j)][methods.index(m)]=mean_squared_error(\n",
    "            test_mi, predictions[N_values.index(j)][methods.index(m)])\n",
    "        MAPE[N_values.index(j)][methods.index(m)]=mean_absolute_percentage_error(\n",
    "            test_mi, predictions[N_values.index(j)][methods.index(m)])\n",
    "        R2[N_values.index(j)][methods.index(m)]=r2_score(\n",
    "            test_mi, predictions[N_values.index(j)][methods.index(m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = sb.heatmap(MAPE,xticklabels=methods,yticklabels=N_values,annot=True)\n",
    "heat_map.set_title('MAPE for different sizes of training and with expanding and sliding methods for Milano')\n",
    "heat_map.set_xticklabels(['Expanding','Sliding'])\n",
    "heat_map.set_ylabel('Number of Training Values [Hours]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(N_values, MAPE[:,0],label='Expanding')\n",
    "plt.plot(N_values, MAPE[:,1],label='Sliding')\n",
    "plt.xlabel('Number of Training Values [Hours]')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('MAPE vs Learning strategy and Training size Milano')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% [OPTIONAL]<br>\n",
    "ilano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mi = Milano.values.astype(float)\n",
    "tr_size_mi = 312 #best size train (312h)\n",
    "ts_size_mi = 72 #size test (168h = 1 week)\n",
    "h_values = range(1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.zeros((len(h_values),ts_size_mi))\n",
    "MAE=np.zeros((len(h_values)))\n",
    "MSE=np.zeros((len(h_values)))\n",
    "MAPE=np.zeros((len(h_values)))\n",
    "R2=np.zeros((len(h_values)))\n",
    "train_mi, test_mi = X_mi[0:tr_size_mi], X_mi[tr_size_mi:(tr_size_mi+ts_size_mi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in h_values:\n",
    "    history = [x for x in train_mi]\n",
    "    for t in range(0, ts_size_mi,h):#for each hour I do arima model\n",
    "        model = ARIMA(history, order=(4,0,1))\n",
    "        model_fit = model.fit(disp=0, method='css')\n",
    "        output,_,_ = model_fit.forecast(steps=h) #get all the forecast\n",
    "         \n",
    "        yhat = output[:h] #first forecast\n",
    "        if t+h>71:\n",
    "            yhat=output[:(72-t)]\n",
    "        predictions[h_values.index(h)][t:t+h]=yhat\n",
    "         \n",
    "        obs = test_mi[t:t+h]\n",
    "        history.extend(obs)\n",
    "        \n",
    "    MAE[h_values.index(h)]=mean_absolute_error(test_mi, predictions[h_values.index(h)])\n",
    "    MSE[h_values.index(h)]=mean_squared_error(test_mi, predictions[h_values.index(h)])\n",
    "    MAPE[h_values.index(h)]=mean_absolute_percentage_error(\n",
    "        test_mi, predictions[h_values.index(h)])\n",
    "    R2[h_values.index(h)]=r2_score(test_mi, predictions[h_values.index(h)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "x=1\n",
    "for i in predictions:\n",
    "    plt.plot(i,label=('h='+str(x)))\n",
    "    x+=1\n",
    "plt.plot(test_mi,color='black')\n",
    "plt.grid()\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('h')\n",
    "ax1.set_ylabel('MAPE')\n",
    "ax1.plot(h_values, MAPE, color='red', label='MAPE')\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.set_ylabel('MSE')  # we already handled the x-label with ax1\n",
    "ax2.plot(h_values, MSE, color='blue', label='MSE')\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.grid()\n",
    "fig.legend()\n",
    "plt.title('MAPE and MSE with different time horizons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Milano.loc['2017-01-30 00:00:00':'2017-02-02 23:59:59'].astype(float)\n",
    "model = ARIMA(train, order=(4,0,1))\n",
    "model_fit = model.fit(disp=0)\n",
    "#print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = Milano.loc['2017-01-30 00:00:00':].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lot data for future day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = model_fit.plot_predict('2017-01-30 00:00:00', '2017-02-05 23:59:59', dynamic=False,\n",
    "                             ax=ax, plot_insample=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
